{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"kc_house_data.csv\")\n",
    "data = data.drop([\"id\", \"date\", \"zipcode\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            540088.141767\n",
       "bedrooms              3.370842\n",
       "bathrooms             2.114757\n",
       "sqft_living        2079.899736\n",
       "sqft_lot          15106.967566\n",
       "floors                1.494309\n",
       "waterfront            0.007542\n",
       "view                  0.234303\n",
       "condition             3.409430\n",
       "grade                 7.656873\n",
       "sqft_above         1788.390691\n",
       "sqft_basement       291.509045\n",
       "yr_built           1971.005136\n",
       "yr_renovated         84.402258\n",
       "lat                  47.560053\n",
       "long               -122.213896\n",
       "sqft_living15      1986.552492\n",
       "sqft_lot15        12768.455652\n",
       "dtype: float64"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            7.700000e+06\n",
       "bedrooms         3.300000e+01\n",
       "bathrooms        8.000000e+00\n",
       "sqft_living      1.354000e+04\n",
       "sqft_lot         1.651359e+06\n",
       "floors           3.500000e+00\n",
       "waterfront       1.000000e+00\n",
       "view             4.000000e+00\n",
       "condition        5.000000e+00\n",
       "grade            1.300000e+01\n",
       "sqft_above       9.410000e+03\n",
       "sqft_basement    4.820000e+03\n",
       "yr_built         2.015000e+03\n",
       "yr_renovated     2.015000e+03\n",
       "lat              4.777760e+01\n",
       "long            -1.213150e+02\n",
       "sqft_living15    6.210000e+03\n",
       "sqft_lot15       8.712000e+05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            1.347824e+11\n",
       "bedrooms         8.650150e-01\n",
       "bathrooms        5.931513e-01\n",
       "sqft_living      8.435337e+05\n",
       "sqft_lot         1.715659e+09\n",
       "floors           2.915880e-01\n",
       "waterfront       7.485226e-03\n",
       "view             5.872426e-01\n",
       "condition        4.234665e-01\n",
       "grade            1.381703e+00\n",
       "sqft_above       6.857347e+05\n",
       "sqft_basement    1.958727e+05\n",
       "yr_built         8.627973e+02\n",
       "yr_renovated     1.613462e+05\n",
       "lat              1.919990e-02\n",
       "long             1.983262e-02\n",
       "sqft_living15    4.697612e+05\n",
       "sqft_lot15       7.455182e+08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms         0.308350\n",
       "bathrooms        0.525138\n",
       "sqft_living      0.702035\n",
       "sqft_lot         0.089661\n",
       "floors           0.256794\n",
       "waterfront       0.266369\n",
       "view             0.397293\n",
       "condition        0.036362\n",
       "grade            0.667434\n",
       "sqft_above       0.605567\n",
       "sqft_basement    0.323816\n",
       "yr_built         0.054012\n",
       "yr_renovated     0.126434\n",
       "lat              0.307003\n",
       "long             0.021626\n",
       "sqft_living15    0.585379\n",
       "sqft_lot15       0.082447\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['price'].drop(['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficient\n",
    "All features have a positive correlation and the biggest ones seem to be sqft_living, sqft_above, and grade followed by bathrooms and sqft_living15. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas.read_csv(\"train.csv\")\n",
    "train = train.drop([\"zipcode\"], axis=1)\n",
    "train = train.drop(train.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop(['price'], axis=1)\n",
    "y = train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.47042805e+04,  2.56877840e+04,  8.30842103e+01,  3.75929764e-01,\n",
       "        1.55555810e+04,  7.15535170e+05,  6.30278980e+04,  1.88164028e+04,\n",
       "        7.95346027e+04,  4.20104951e+01,  4.10737150e+01, -2.40066933e+03,\n",
       "        4.36829418e+01,  5.53505032e+05, -7.42402712e+03,  6.80157923e+01,\n",
       "       -5.15527568e-01])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(x, y)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 31486167775.794872, r^2: 0.7265334318706018, rse: 177443.4213370416\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "mse = mean_squared_error(y, pred)\n",
    "r2 = r2_score(y, pred)\n",
    "rse = math.sqrt(mean_squared_error(y, pred))\n",
    "print(\"mse: {}, r^2: {}, rse: {}\".format(mse, r2, rse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScaled = train.copy()\n",
    "trainScaled = trainScaled - trainScaled.mean()\n",
    "trainScaled = trainScaled / trainScaled.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.27106556e-02,  5.78674496e-02, -6.49597640e+12,  3.10876091e-02,\n",
       "        2.39523529e-02,  1.87565475e-01,  1.42141920e-01,  3.92609015e-02,\n",
       "        2.72242854e-01,  5.78010557e+12,  3.29871342e+12, -2.00223703e-01,\n",
       "        5.15966007e-02,  2.32731749e-01, -1.31850540e-03,  1.31589596e-01,\n",
       "       -3.82068419e-02])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled = trainScaled.drop(['price'], axis=1)\n",
    "y_scaled = trainScaled['price']\n",
    "modelScaled = linear_model.LinearRegression()\n",
    "modelScaled.fit(x_scaled, y_scaled)\n",
    "modelScaled.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.2732457258827541, r^2: 0.726480754872115, rse: 0.522729113291726\n"
     ]
    }
   ],
   "source": [
    "pred_scaled = modelScaled.predict(x_scaled)\n",
    "mse = mean_squared_error(y_scaled, pred_scaled)\n",
    "r2 = r2_score(y_scaled, pred_scaled)\n",
    "rse = math.sqrt(mean_squared_error(y_scaled, pred_scaled))\n",
    "print(\"mse: {}, r^2: {}, rse: {}\".format(mse, r2, rse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the models\n",
    "\n",
    "In comparison to the other model, this one has about the same r^2 value, but the MSE is much lower. This is becaues all the features were scaled so  the large MSE before was attributed to the large response values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pandas.read_csv(\"test.csv\")\n",
    "test = test.drop([\"id\", \"date\", \"zipcode\"], axis=1)\n",
    "test = test.drop(test.columns[0], axis=1)\n",
    "testScaled = test.copy()\n",
    "testScaled = testScaled - train.mean()\n",
    "testScaled = testScaled / train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.drop([\"price\"], axis=1)\n",
    "y_test = test[\"price\"]\n",
    "x_test_scaled = testScaled.drop([\"price\"], axis=1)\n",
    "y_test_scaled = testScaled[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non scaled model\n",
      "mse: 57628154705.669876, r^2: 0.6543560876120986, rse: 240058.64847088905\n",
      "\n",
      "scaled model\n",
      "mse: 0.5006894559398107, r^2: 0.653891136597871, rse: 0.7075941322112633\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "y_test_scaled_pred = modelScaled.predict(x_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "rse = math.sqrt(mse)\n",
    "print(\"non scaled model\\nmse: {}, r^2: {}, rse: {}\\n\".format(mse, r2, rse))\n",
    "mseScaled = mean_squared_error(y_test_scaled, y_test_scaled_pred)\n",
    "r2Scaled = r2_score(y_test_scaled, y_test_scaled_pred)\n",
    "rseScaled = math.sqrt(mseScaled)\n",
    "print(\"scaled model\\nmse: {}, r^2: {}, rse: {}\".format(mseScaled, r2Scaled, rseScaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D\n",
    "\n",
    "The features taht have the most impact are sqft_living, sqft_above, and sqft_basement. This makes sense because the price of a house does depend a lot on how big it is. What is surprising is that number of bedrooms did not seem to have a major impact on the price. I expected the more bedrooms the more the price, but I think bedrooms and sqft_living are heavily tied. The model is fitting the data well as the r^2 is .65 which means the model can handle a reasonable amount of variability. The error is quite large however as the RSE is large meaning some predictions will be very inaccurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft_living = train[\"sqft_living\"]\n",
    "price = train[\"price\"]\n",
    "xBar = sqft_living.mean()\n",
    "yBar = price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "denom = 0\n",
    "for i in range(len(sqft_living)):\n",
    "    num += (sqft_living[i] - xBar) * (price[i] - yBar)\n",
    "    denom += (sqft_living[i] - xBar)**2\n",
    "theta1 = num/denom\n",
    "theta0  = yBar - (theta1 * xBar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269.46205468469446"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32304.6547210266"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJztnXmcVcWZ979Pb0Cz0yCydTcoyKLi0lFcwChREWk1MyavBpW4DAnqjCZmAg6Z0cwM8yZmkox5k6hk1JjQiTrGSeRG3DXghqIRBBukRUB2AQHZ6e7n/ePUhduXu5y7L/18P5/63HPr1DlVdfp2/U7VU/WUqCqGYRiGkQoluS6AYRiGUfiYmBiGYRgpY2JiGIZhpIyJiWEYhpEyJiaGYRhGypiYGIZhGCljYmIYhmGkjImJYRiGkTImJoZhGEbKlOW6ANmid+/eWltbm+tiGIZhFBTvvPPOVlXtEy9duxGT2tpaFi1alOtiGIZhFBQissZPOhvmMgzDMFLGxMQwDMNIGRMTwzAMI2VMTAzDMIyUMTExDMMwUsbExDCMwqGhAWproaTE+2xoyHWJDIeJiWEY/sllY97QAFOnwpo1oOp9Tp1qgpInmJgYhuGPXDfmM2fC3r1t4/bu9eKNnGNiYhiGP3LdmK9dm1i8kVXiiomIdBSRt0RksYgsE5Hvu/jBIrJQRJpE5DERqXDxHdz3Jne+NuRed7r4FSJycUj8BBfXJCIzQuITzsMwjAyR68a8ujqxeCOr+OmZHAAuUNXRwCnABBEZA/wQ+KmqHg98Btzo0t8IfObif+rSISIjgauAUcAE4JciUioipcAvgEuAkcDVLi2J5mEYRgbJdWM+axZUVraNq6z04o2cE1dM1GO3+1ruggIXAE+4+EeAK9zx5e477vx4EREX/6iqHlDVj4Em4AwXmlR1laoeBB4FLnfXJJqHYRiZIteN+eTJMHs21NSAiPc5e7YXb+QcXzYT14N4D9gCPA98BOxQ1WaXZB0wwB0PAD4BcOd3AlWh8WHXRIuvSiIPwzAyRT405pMnw+rV0NrqfZqQ5A2+vAaragtwioj0AP4XGJ7RUqUJEZkKTAWotnFVw0idyZOtATciktBsLlXdAbwMnAX0EJGgGA0E1rvj9cAgAHe+O7AtND7smmjx25LII7y8s1W1TlXr+vSJ647fMAzDSBI/s7n6uB4JItIJuBBoxBOVK12yKcCf3PFT7jvu/Euqqi7+KjcTazAwFHgLeBsY6mZuVeAZ6Z9y1ySah2EYhpED/PRM+gEvi8gSvIb/eVUNANOBb4tIE5694kGX/kGgysV/G5gBoKrLgMeBD4BngFtUtcXZPG4FnsUTqcddWhLNwzAMI2XMZUtSSHt5oa+rq1PbadEwjJgEV/mHLs6srGzXs8ZE5B1VrYuXzlbAG4ZhBMn1Kv8CxsTEMAwjSK5X+RcwJiaGYRhBcr3Kv4AxMTEMwwiS61X+BYyJiWEYRpB8WOVfoPhaAW8YhtFusFX+SWE9E8MwDCNlTEwMwzCMlDExMQzDMFLGxMQwDMNIGRMTwzAMI2VMTAzDMIyUMTExDMMwUsbExDAMw0gZExPDMAwjZUxMDMMwjJQxMTEMwzBSxsTEMAzDSBkTE8MwDCNlTEwMwzCMlDExMQzDMFLGxMQwDMNIGRMTwzAMI2XiiomIDBKRl0XkAxFZJiK3ufi7RWS9iLznwsSQa+4UkSYRWSEiF4fET3BxTSIyIyR+sIgsdPGPiUiFi+/gvje587Xx8jAMwzCyj5+eSTNwh6qOBMYAt4jISHfup6p6igtPA7hzVwGjgAnAL0WkVERKgV8AlwAjgatD7vNDd6/jgc+AG138jcBnLv6nLl3UPJJ+CoZhGEZKxBUTVd2oqu+648+BRmBAjEsuBx5V1QOq+jHQBJzhQpOqrlLVg8CjwOUiIsAFwBPu+keAK0Lu9Yg7fgIY79JHy8MwDMPIAQnZTNww06nAQhd1q4gsEZGHRKSnixsAfBJy2ToXFy2+Ctihqs1h8W3u5c7vdOmj3cswDMPIAb7FRES6AH8AblfVXcB9wHHAKcBG4McZKWEKiMhUEVkkIos+/fTTXBfHMAyjaPElJiJSjickDar6JICqblbVFlVtBX7FkWGm9cCgkMsHurho8duAHiJSFhbf5l7ufHeXPtq92qCqs1W1TlXr+vTp46eqhmEYRhL4mc0lwINAo6r+JCS+X0iyLwNL3fFTwFVuJtZgYCjwFvA2MNTN3KrAM6A/paoKvAxc6a6fAvwp5F5T3PGVwEsufbQ8DMMwjBzgp2dyDnAtcEHYNOB7ROR9EVkCnA98C0BVlwGPAx8AzwC3uB5MM3Ar8CyeEf9xlxZgOvBtEWnCs4k86OIfBKpc/LeBGbHySOVBGEa7oqEBamuhpMT7bGjIdYmyR3uuewYR70W/+Kmrq9NFixbluhiGkXsaGuD66+HQoSNx5eXw8MMweXLuypUNGhpg6lTYu/dIXGUlzJ5d/HVPEhF5R1Xr4qYzMTGMdkbv3rBt29HxVVWwdWv2y5NNamthzZqj42tqYPXqbJemIPArJuZOxTDaG5GEJFZ8MbF2bWLxhm9MTAzDaD9UVycWb/jGxMQw2htVVYnFFxOzZnk2klAqK714IyVMTAyjvXHvvVBR0TauosKLL3YmT/aM7TU1IOJ9mvE9LZTFT2IYRlERbDhnzvRsBdXV3pt5e2lQJ09uP3XNIiYmhtEesQbVSDM2zGUYhmGkjImJYRjFR6RV7qmufLeV8zGxYS7DMIqL8FXua9Z4K/5F4ODBI3FTp3rHfob7It0zkevbAbYC3jCM4iLaKvdI+F353o5XztsKeMMw2ieJrGb3m9ZWzsfFxMQwjOIikdXsftPayvm4mJgYhlFcRFrlXl5+9ELNRFa+28r5uJiYGIZRXERa5f7ww/DQQ8mvfLeV83ExA7xhGIYRFTPAG4Zh5Ip2uCbF1pkYhmGkk3a6JsV6JoZhGOlk5sy22wKD933mzNyUJ0uYmBiGYaSTdromxcTEMIzItMNx/7TQTtekmJgYhnE0wXH/NWtA9ci4vwlKfNrpmhQTE8MwjqadjvunhXa6JiWumIjIIBF5WUQ+EJFlInKbi+8lIs+LyEr32dPFi4j8TESaRGSJiJwWcq8pLv1KEZkSEn+6iLzvrvmZiEiyeRiGkQba6bh/2pg82XMA2drqfRa5kIC/nkkzcIeqjgTGALeIyEhgBvCiqg4FXnTfAS4BhrowFbgPPGEA7gLOBM4A7gqKg0vzdyHXTXDxCeVhGAVHvtol2um4v5E8ccVEVTeq6rvu+HOgERgAXA484pI9Alzhji8HfqMebwI9RKQfcDHwvKpuV9XPgOeBCe5cN1V9U73l+L8Ju1cieRhG4ZDPdol2Ou5vJE9CNhMRqQVOBRYCfVV1ozu1CejrjgcAn4Rcts7FxYpfFyGeJPIwjMIhn+0S7XTc30ge32IiIl2APwC3q+qu0HOuR5FRJ1/J5CEiU0VkkYgs+vTTTzNUMsNIkny3SxTCuH++DhO2Q3yJiYiU4wlJg6o+6aI3B4eW3OcWF78eGBRy+UAXFyt+YIT4ZPJog6rOVtU6Va3r06ePn6oaRvYwu0Rq5PMwYTvEz2wuAR4EGlX1JyGnngKCM7KmAH8Kib/OzbgaA+x0Q1XPAheJSE9neL8IeNad2yUiY1xe14XdK5E8DKNwMLtEauTzMGE7xI+jx3OAa4H3ReQ9F/dPwA+Ax0XkRmAN8FV37mlgItAE7AWuB1DV7SLyb8DbLt2/qup2d3wz8GugEzDPBRLNwzAKiuCw0cyZ3tBWdbUnJPk4nJSP5PswYTvD9jMxDKMwqa31hrbCqanxbDxGWrD9TAzDKG5smDCvMDExDKMwsenLeYVtjmUYRuEyebKJR55gPRPDMAwjZUxMDMMwjJQxMTEMwzBSxsTEMAzDSBkTE8MwDCNlTEwMwzCMlDExMQzDMFLGxMQwDMNIGRMTwzAMI2VMTAzDMIyUMTExDMMwUsbExDAMw0gZExPDMAwjZUxMDMMwjJQxMTEMwyhGGhq83ShLSrzPhoaMZmdiYhhG4ZPlhjPvaWiAqVO9bY1Vvc+pUzP6XExMDMMobHLQcOY9M2fC3r1t4/bu9eIzhImJYRiFTQ4aznzlk+17+eUrTdxUdx0aKcGaNRnL27btNQyjsFm7NrH4ImPTzv0Elmxg7pKNLP5kBwCn9ujDZ5260WvfrraJRbweWwa2OjYxMQyjsKmujvzGXV2d/bJkia27DzDv/Y3MXbyRt9dsRxVOHNCNGZcM59KT+jFo3g546POjL1T1emwZEJO4w1wi8pCIbBGRpSFxd4vIehF5z4WJIefuFJEmEVkhIheHxE9wcU0iMiMkfrCILHTxj4lIhYvv4L43ufO18fIwjHaBGZvbMmsWVFa2jaus9OKLiB17D/LoW2u55r8XcsasF/jnPy1jx76DfOtLw3jpjvMI/P1YvnnecQzqVemJhUYc6Mpcj01VYwZgHHAasDQk7m7gOxHSjgQWAx2AwcBHQKkLHwFDgAqXZqS75nHgKnd8PzDNHd8M3O+OrwIei5VHvHqcfvrpahgFz5w5qpWVql5T4YXKSi8+l2WqqVEV8T4zXZZI+WW7DFli176D+od3PtGvP7RQj7vzz1ozPaDn3fOS/uezy3X5xl2xL66pafs7CYaamoTKACzSOO2rqsYf5lLV+aG9gjhcDjyqqgeAj0WkCTjDnWtS1VUAIvIocLmINAIXAF9zaR5xQnWfu9fdLv4J4OciIjHyeMNnGQ2jcIllbM7A0EVcgjOpgmUKzqSCzJQnWn6zZ8Pq1enPLwfsPdjMi41bCCzZwMsrPuVgcysDenTixrGDqT+5P6P6d8NrCuMwa1bbZwUZ7bGlYjO5VUSuAxYBd6jqZ8AA4M2QNOtcHMAnYfFnAlXADlVtjpB+QPAaVW0WkZ0ufaw82iAiU4GpANVFPH5qtCPyzdicbXHLNzFNE/sPtfCXDz9l7uINvNi4hX2HWjimawcmn1lN/ej+nDqohz8BCSX4PGbO9H4f1dWekGToOSU7Nfg+4DjgFGAj8OO0lSiNqOpsVa1T1bo+ffrkujhGsZJNG0a0l6JsvywF6xxtqmky4ubnOeabmKbAoZZWXl6+hW8//h5f+PcX+MZv3+H1j7bxt6cP4NGpY3jjzvHcVT+K06p7Ji4kQSZP9npsra3eZwYFN6meiapuDh6LyK+AgPu6HhgUknSgiyNK/Dagh4iUud5JaPrgvdaJSBnQ3aWPlYdhZJdsD/NkeegiIuF1jkSi4ub3ORb4zK2WVuXNVduYu3gDzyzbxI69h+jWsYxLTjqWSSf35+zjqigrLdDlf34MK0AtbQ3w/UKOv4VnwwAYRVvj+Co843uZOx7MEQP8KHfN/9DWAH+zO76Ftgb4x2PlEa8OZoA3MkKajJwJkWtjc7Q6pzIhwO9zzMcJCHFoaWnVhau26T//8X09/d+e05rpAR35z/P0tt+/qy98sEkPHGrJdRFjgk8DvGi06WMOEfk98EWgN7AZuMt9PwVQYDXwDVXd6NLPBG4AmoHbVXWei58I/JcTl4dUdZaLHwI8CvQC/gpco6oHRKQj8FvgVGC7E5xVsfKIRV1dnS5atCheMsNIjJKSyFMwRbyhhWIkWp0Bamr8j8s3NBwZz492v0jPMfS6DNsBkkVVWbxuJ3MXb+DPSzayadd+OpaXMH54Xyad3I/zhx9Dx/LSXBfTFyLyjqrWxU0XT0yKBRMTIyNEsxvU1BTN7KKjSEedGxrghhvg4MHY6dL5HDMsQqrKBxt3EViykcCSDXyyfR8VpSWMG9aH+tH9+NKIvnTuUHjrxP2KSeHVzDDyiXywYWSbdNT5ttviC0k6n2MGbVtNWz7nqTnPEWjawapux1La2sK53Vr5hytP56JRx9K9U3mKhS8Q/IyFFUMwm4mRMaZNUy0t9cbvS0u97/lEJmwsqd4zls0lE+WMlleStq3VW3frz19aqRf/9C9aMz2gtd99Sq+6apY2jL5Yt3Xqlvd2nEQgXTaTYsGGuYyMEGlmU2Wlt4guH8bx87V8saa6pqtN8jPrLAHb1oYd+/jzko3MXbKBJet2AlBX05NJTz7AxDfmcsyez9peUCRDnWYzCcPEpB2SDUNtpm0mqdYhX206vXvDtm1Hx1dVwdat6ckj1jqYIHGew5bP9/P0ko0Elmxk0RpPLE4e2J1JJ/fj0pP7M6BHp6KfhOFXTHI+/JStYMNc7YxYU0jTOewjEn2oJpN1iJQ2Up0yUb50PL85c1TLy9uWqbw8vUND0eoe51lu231AG95co1c98IYOnhHQmukBvfinf9Gfv7RSP/5099H55GJ6eBbB5zBXzhv5bAUTk3ZGtH/wqqr0rlPIZEOSyNqLioq2aSoqYtsLki1fOtd5ZHq9TDxbSUh+O/Ye1MffXqvXPbhQhziHiuf/58v64+dW6Ieb4jhULMC1L4lgYmJi0r6J91aaj42r3zqE9yqqqqILZ7rLV0hv4XHqvnv/If3jX9fpjb9+W4f+09NaMz2g5/zgRf3BvEZdun6Htra2JpZXEXotVvUvJmYzMYoTP+PloaQyvp0J20xDA1x7beSx+HC7QjxjdjrLV2j2gbC67/+3Wbxy6gXMXbyRF5dvZv+hVo7t1pFLT+5H/ej+jB7YPXk/WEWKGeDDMDFpZ0SbxdSpU2TDb64N0qHEm4WUqJikk3w16MfgYHMrC1Z+SmDJRp5btok9B1vo3aWCiSf1Y9LJ/amr6UlJiQlINGzRotG+ieZ+G/J/kWEkN+uhbN/e9ntVVfSZUemmQBZpNre08kbQoeLSTeza30z3TuXUj+5P/ej+nDm4V+YdKhaA25d0YmJiFC+TJ0f/583nf/J47tR79Wr7/d574frr4dChI3Hl5V58usnyHhmJ0NKqvL16O4ElG5j3/ia27TlIlw5lXDSqL/Un9+ec43tTUZYlj7zZ9iadD/gxrBRDMAO8kVHSaYCN55W3qio9+WfSaJwlg3Rra6u+s2a73v3UUj1j1vNaMz2gw783T29peEefWbpR9x1szki+cSmkiQpxwAzwbTGbiZEx0r3KPJbxHdJj7M7kyvgMr7pXVZZt2MXcJRsILN7I+h37qCgr4fwT+jDp5P6MH3EMlRU5HnQptIkKMTADfBgmJkbGyIRROpZRPR3G7kwa0jN07w83f87cxRsILNnIx1v3UFYijB3am/rR/blwZF+6dswjh4oFOFEhGmaAN4xskYmtZGtqIjdGIukxdmdy+9to91izxntjj2ZniWCw/vjiKwgs3sDcJRv4cPNuSgTOOq6Kb4wbwsWjjqVn54rUy5sJCmSiQjoxMTGMVMnEVrKRGiMR+OY302PAzeT2t9HuDd7QTyRjdMjQ2LpufQj0rSPw4naWvv8KAGfU9uJfLx/FJSf2o0/XDqmXMdPk8USFjOHHsFIMwQzwRsZIZpW5HwN1pg3kfsqcrGE//N5xjNGbTjhZHzz9Mr3imv/UmumeP6zLrv2x/urCr+uGHXvTV28jYTB3KiYmRhZJpNGN5OQwis+ojJYrXpmTdcUyZ050Fy8hYWunbvqbUyfqV6//idZ+9ymtmR7QS75+r/7izCt1Tfe+R9IWkWuSQsSvmJgB3jCyQag9AGKvTM+XWVXJGJEj5SlyuL47O3Tm2WFnM3fEWF6vGU1LSSnHb11L/fIFTGqcz3Hb1x99z3zYf6UdY7O5wjAxMXKGn02awsmHWVXRprcG7xHJBhAhz90VnXh+6BgCw8cyf/CpHCotp+azDUxqXEB943xO2LoGgTaik3SZY9HOVqSnCxOTMExMjJyRqNNJSH49QmiDGe1/2++945U7Uo/BCdC+sg68dFwdgRHjeGlIHQfKO9B/z3YmLXuFSY3zOWlTEwl5w0p1fUa+7jhZAPgVkyz5FjCMJGho8Bq0khLvs6Eh1yVKjmSm2yYzqyrYYK5ZE3sYLdQdS6xnPGuW1+BGY+9eT7gcB5pbeH7MpfxD/Xc4/e/ncMsVd7JowAiuXvwsf3j+P3n13mv4p5ce5OQOhyILSU2NFyKR7PMI1m3KlKN7hmHlN1LEj2GlGIIZ4AuMYtpwKJ57lPCQbD395hPcOCvSM66o8IznQaP8tGkx73uwtExfXr5Z73j8PT3xrme0ZnpAT/mH3+mMi2/R16pP0mYpObo+8XbBTMff3e+MsnTsiFnkkK7ZXMBDwBZgaUhcL+B5YKX77OniBfgZ0AQsAU4LuWaKS78SmBISfzrwvrvmZxwZeks4j1jBxKQACJ1dVFoa+Z8/V76NUpmmG6lhKy8/0mhXVbVtwIP3TjTPRDYEq6nxJz7BhjwkbbOU6GvVJ+mMi2/RU25/VGumB/TEu57ROx5/T19evlkP/jbFac/pmBLtV1gL0FdWtkmnmIwDTgsTk3uAGe54BvBDdzwRmOca/DHAQj0iDKvcZ093HBSHt1xacddekkwe8YKJSZ6Tz2+S6ViTkWgDmcwbeiI9IBH/4lNToy2/naNvH3eq3jV+qtbd8hutmR7QEd96Qv/+P57U55Zt0v2/8Vm/bO1I6KduhdrTzTJpExPvXtSGickKoJ877gescMcPAFeHpwOuBh4IiX/AxfUDlofEH06XaB7x6mBikudk6k0yk2+5wfsFz4c3YKk0VtHWacSqfyQBitao+uiZtIIuPvZ4/ffzb9Sz/uMFrZke0GF3PKnfvOJODZx7he79zZzo+UYT23jp0vH3mjMnes+2tLQot9bNJJkWkx0hxxL8DgSAc0POvQjUAd8BvhcS/88urg54ISR+LBBIJo8o5Z4KLAIWVVdXZ+5pG6mTjjfJ8IZo2rT0jL/HKlu83lQywyhz5sS/p983/1jPIELj3gr6QZ9avWfstTp26q+0ZnpAj//OH/WGh9/S/313nX6+/9DRefp1tx4vXTrsJbF6uNYTSYqsiYn7/plmUEz85BGvDtYzyXOiNTR+3yTnzPGMx8n2bkJ7GMG32vCeR6SyxcsrmWG5RGwZfvAx/NZUNVB/ev4UHX/jL7VmekCH/OOf9Jqv/qs+dvqluuORhtj3j1XOUKKJcvAZpWMPkFh/KxOSpLBhLhOTwiLVt1If7juiNvDx3majvd0nK1zxSNSQnmQjufah3+kvJtykE77+M62ZHtDa7z6lX736/+pvT7lEt3bq5pVj2rQjzyiaIMUaUgolnljEE5tUnl17nLWVJvtUpsXkR7Q1jt/jji+lrXH8LRffC/gYz/je0x33cufCDfATk8kjXjAxKQBS+fH7bXwjNfDxegKhPZTQssUTsGQdJyY6lRi8svh4Xht27NVfzf9IL7v7j4cdKn75mh/pg6dfppu69Ipe91hC77dnEu8+meyZtLdZW2mcWp82MQF+D2wEDgHrgBuBKje8tBJ4IUQYBPgF8BHedN+6kPvcgDedtwm4PiS+Dljqrvk5R6YGJ5xHrGBikiCRxt6zMQsnWfw2uqFTcoP18NMTiFTnWGISqXFPxVDtJwTrEVbWLbv26yOvf6xX3vfaYQG59O9+qfef8Tf6Sbc+8e8Zr4FOpAGPN+SWCZtJe7SVpFFU09ozKYZgYpIAfhqzfPsH9TvMFW5Xqaz0f214nf2IUEnJkX/iRGZojR/vr0xRwvZex+jvfva4fu1Xb+jgGZ6AXPSTv+jPXvhQV326O6FpwXGHjtLZgKdrNlc+v/hkgzQO95mYhAUTkwTIxYKvVBuAOXOiu3X32+AnWudkhqPiNdrBuvsx7oeFnRWV+sSoC/TrV96lx33HG8b64o9e1h8/u1xXbNrV9jn7Fc9p0/wtIC20nmyxYz0TE5O8IBEDcDoaiWTfbKM1YME3sHQ19NHe7PwOkWUw7CnvoE8NH6t/9+WZOvSOJ7VmekDP/uaD+h/nfV3f73uctra2xn7OoSF8VX6XLtHTxvr72FBT7slHm0mxBBOTBEjkjTsdjUQyY+6RBCO0LIm8gScSwss0bVp2BaWkRPd1rNR5Q8/SWy77rg7/1hNaMz2gX7j5Eb17/N/pO/1P0NZg2qoq/3/X0N5DPNGJN83WjOD5QZZnc5kLeuNoEt1/I9W9Jvzum+GnXOFliXXvRInmsjzo9t2Pm/lYe3bE4GBJGa/VnsLcy2/iuY4D2N0q9Nq7k4nLX2XS8gV8Yd0HlGqYi/bycrjpJnj66cRc0sdzPR/PHXy0Z56qG3kjJ/h1QV+WjcIYBUawsQzdSGjiRLjvvsjpE92rI5zq6uj3WLPGE5BgeeIJ3Jo1XmMW3Pwo1r0TZe9euO22I9/DN1oCuOEGOHgw+j0SEJJmKeHN6pMIjBjHvGFns7NTV7p1LGPiicdSP7o/Zy18jrKf3x/9nocOwf0xzgcJd+8ez2V+PHfw0Z55Mm7kjcLBT/elGIINc6WBaMMXIkfcc8TqVkc772f2WKxZRbGG4CItOEw1lJYebewPdVGSiEE/LLQgunDgKP3ehd/U02/9rdZMD+jI2x/X2//Pv+gLH2zSA4da2j7HWHYNv88o/O8UazisoiK+cd1sJkUFZjMxMUk7sQzOVVWxG5B4DUw8G0es9Q7xRChbdo2qqqQmALSC/rXfMP3XC27SM2/+tdZMD+gJ335Cb758us4bdpbuK6uIPQ23oiLx+sVzDx/tfp07J+9B2absFiR+xcRsJkZiSEKbrR6xYUQbhy8thUceOTK0Fmvf8lmzjraZxLNBiKR3qCsRYpRNgQ+OGUxg+DgCI8bySY9jqWg+xHmrFjFp+QK+1PQWnQ/tP3JBvOdYVQX79vmzc/mxcSX7d46GbZtbsPi1meS8x5CtYD2TNJFo7yD4Rh3P824yPZjg+ofgdNZI905ivUZaQ1j+H1YN0h+f+zU9/6b7DjtUvO4rd+v/nHiB7ujQOfl8gkONfoYD/fQIEn1u8RbD+ZnhZT2XvAQb5jIxSYlE7BuxVpEHG4t4q8yjNSrhuxBOm+YNtSTa0OVQUFb3OFZ/PuYrevH1/++wQ8Wr/88sbRh9sW7r1O3oso4fn7hoh7pxj3Vt+HThaCRaz3jTfrO5ij4WJlgJY2ISFkxMEsBv7yB8PDzWfuJ+jNLp8lGVB4KyrmsffeCML2v9dT857A/rbyf/UH/60jjyAAAVaElEQVR92iTd3LlH7OuDzzpRNy/xnlcijXM0QYpnG0v0fsn490oWmxiQFCYmYcHEJAGS/cdOdZZR+D92uhcdJuKmvqQk4R7Q5s499eHTJunfTL7nsIBcdu1PdPYXvqzru/ZOrKx+6h7+du13UaIfYjW8ybzdx2vIs+E63hZTJoWJSVgwMUkAP//Y8by/JtsTCP3HTndvwu/mWQmEbZ266ZzRE/Sqq2Zp7Xef0prpAb34+v+nPx/zFV3d49i05xezAUx3g5zuIaFY98tGQ297nSSFiUlYMDGJQLR/7nj/2NGGU6qqYjsG9BNC/7Ez4Q4lDWFHh876+Inj9dqvfF+H/OOftGZ6QM+/6T79yTlf05VVA7NTjkhrPWL93fLdVpCNISjrmSSFiUlYMDEJIdp4fKyx9+ACwFQb+OA2vLF25wv9zLHxPBh2l3fUP444T2/8m+/p0Dv+V2umB/Tcb/y3/mDcFF3WZ/ARf1jZCOPHR//7+I0H3xtqRf0NpVucMi14ZjNJChOTsGBi4ohnpA3tfYQKTufO6RkmCt0GNt0r09Mc9pVV6NPDztZpl8/QE77tOVQ88+Zf67+df6P+td+w7AoIHNlGN9EeSKwXgGQa01g903xvmPO9h5aH+BUTW7TY3ojnxA+8BWu9esGuXZ5/p3QSulCtocHzdbVtW3rzSIEDpWUsqD2NwIixPH/8mezpUEnvPZ8xcflr1DfO5/T1jZSQw/+ZmproThujOVKM5+wyUUedsX5DthCx6PC7aNHEpL2RTi+6yRJsvBL1TpwhmqWE12tGM3fEOJ4ddha7Onahx75dXLLidSYtX8CZa9+nLNwjby6pqfHnTSCIXy/AQe/Hoc4rI4lCusXJyGvMa7ARmVy5Fgkl6JXWjxfgDNEiJbw1cBSBEWOZd8I5bK/sTtcDe7jwwzepXz6fc1e/R3lrS+oZiXiNb0sa7gXevXbvjnyupeWIh+VQEYjkhiaU6uqjhT3UW3O4oMT7DcXzOmwUJdYzKUZC3zB79fLitm8/4kr+kUdy3hugtDR9DaxPFHi3/3ACI8by5xPOZUvXKjod3M+XmhYyafkCzlv1Dh1b0jisV1kJnTplfxgvUs8g2pBicFgq2n4s0e4VS5ysZ1JU2DBXGEUvJols0NS5s/fGHO0Nt4hQYFnf45g7YhyB4eeyvntfKpoPcv5Hi6hfPp8LPnqbykMH0p9xkptgpS3vaJtQRRvKSnRDq3jiZDaTosHEJIyiFpM8sT3kEyt61xAYMZa5w8exuld/ylqaGbv6r9Q3zufClW/S9eC+XBfxCNOmebshpmv40W/PIFRYog3F+fEG7MfOYhQsWRETEVkNfA60AM2qWicivYDHgFpgNfBVVf1MRAS4F5gI7AW+rqrvuvtMAb7nbvvvqvqIiz8d+DXQCXgauE1VNVoescpa1GLSu3dezYjKFat69icwYhyB4WP5sE8NJa0tnL12CZMaFzDhw9fpsT8Pe2Khxu9YLwSlpdCjR/y/c6yeQfjw5+efx94V0noZBllyQY/XkPcOi7sHmOGOZwA/dMcTgXmAAGOAhS6+F7DKffZ0xz3dubdcWnHXXhIrj1ihaNeZzJmT8/UYuQxrux2j953xtzpxyn8d9sj7la/9QH9z6kTdUhnHoWI+hHBvyYkuJi0vb+tVOdq6Cb/reoKLSm0NhuEgG+tMXM+kTlW3hsStAL6oqhtFpB/wiqqeICIPuOPfh6YLBlX9hot/AHjFhZdVdbiLvzqYLloescpatD0TP+tGioxNXar48/BzCAwfx18HDAfglA3LmdS4gEtXvEq/zwukl1ZRAQ89dPSbf7g9onNn73PPHu+zpMTrzQQ3DPPTc/D7O4llbzHaJdmaGqzAcyKiwAOqOhvoq6ob3flNQF93PAD4JOTadS4uVvy6CPHEyKP90U6mYW6t7M68YWczd8Q43h40CpUSRm7+iOmvPMyk5a8yaOfmXBcxcbp2jX5uX4hNJygiQVpbPSGKJiThdoyJE/2/cFRX+0uXScwOU5CkKibnqup6ETkGeF5EloeeVFV1QpMxYuUhIlOBqQDV+fBPkgnyYd1IhtjZoTPPnHA2geFjeb1mNC0lpRy/dS23v/o7Ji1fwHHb1+e6iP4oL4eHH/aOQ+0i27bBtdfCa6/BL395JL2f9TcHD3rpgulDhSN06veaNXDfff7KWVnpNdy5JJH1LkZ+4WcszE8A7ga+A6wA+rm4fsAKd/wAcHVI+hXu/NV4vRpC07lzy0PiD6eLlkesUNQ2k0jO63JtC0gy7KropE+O/KJe/7f/osd/x3OoOG7qbP3R2Gu0sXdN9v1hJRuCDir9eGMObrkbJBHnluF/60Su9WtvySbm2TfvINOOHoHOQNeQ49eBCcCPaGscv8cdX0pbA/xbLr4X8DGe8b2nO+7lzoUb4Ce6+Ih5xApFJyaxtrZNZJe+PAh7yzro3OHn6jeuuFOH3vGk1kwP6FnTHtJZX7xel/Q9rnAEJF4DGKuhD03r1zNzqvvb54N4hGN7juQd2RCTIcBiF5YBM118FfAisBJ4IUQYBPgF8BHwPp7hPnivG4AmF64Pia8Dlrprfs6RqcwR84gVikpM/HhtzXMx2V9aps8ef6beWv+POuJb/6M10wNad8tv9K7xU3XRgOHaQn64nk85+N0JMXzjsfLy2PdN1YNzvr7pW88k7/ArJrZosRDx47X12mu9f8M84lBJKa/WnkJg+FieG3YWn3foTM+9O7lkxevUN87njHXLKM0nh4rporwcunWLvUYkdHFgQwPccEP0NSBVVXDvvdE9HsRbfZ/P60cirbfJ5/K2A8zRYzETy+C+d6/XyPTqlRcLGVukhIWDTmTuiLE8M+xsPqvsTtf9u5ngPPKevWZxehwq5jOHDsX+W4QbvmfOjCwkkVajhze85eXeTK/gDLCqKvjqV70V9oUwOypYLpvNVXBYz6QQ8eNGvqwMmpuzU54wWhHeHTCcuSPG8fQJ5/Bpl15UHtzHhSsXUt84n7Gr36VDS27KljeUlnpTfCM1lon4yYq3qt3vW71NxzWiYL65wigKMfHrzDFHHnmXHDuUwIixBIaPZWO3PnQ4dIALVi2ivnE+53+0iE7NGXCoWKjEWhwYzT1OPD9Z0YY//fjXsqElIwo2zFVs+HXmWF6e/t0Ro6DA8j61ziPvWNb27Ed5yyHOW/Uu0//yCF9qWkiXfHKomE9EW/fU0ODtcBlOcJFiLKItYI23sDXSupbgcKmJieETE5N8xo9X13BEMl6spl4DPY+8I8bxUdUgSltbOHvNYm594zEu/vANuh/YE/8m7YWSEm/IMdwGsnu39/cNb6xnzoz8MtC1a/yGPdoC1ngLdpMVIcMIwcQkn4g1/h1PSCoqvAYnQ0b3td37Hu6BNPYdgmgrZ65dyvWLnuKSFa9RtS/C23R7p6wMfv1r7zh8749t29qu7I43hLl9e/z8Iu2o6GdVe7IiZBghmM0kX0hlT5KaGs+Nhl+3GT7Z2LWKPw/39gRZ3H8YAKetb6S+cT4TV7xG390+Grj2TFUVbHU+UKPZM4L2rXjTeZPZo8SvId1sJkYMzAAfRt6LSbLef7t08RqhcGeASfJpZQ/mnXDOYYeKACdtXMmk5Qu4dPkCBu76NC35tAtCjex+ZuBFIxsNu83mMqJgYhJGzsUk3j+r38YmA9vBftax62GHim9Un0RrSSknfLqa+sb5XLr8VQZ/tiGt+bUbQnsTyb4sJOJm3jAygM3myif8eEL14/23shI6dUqLXWRXRSXPDx3D3BHjeLX2FJpLyxi8fT23vvE4k5YvYNhWM76mRLitIpI9Ix5+h7YMIw+wnkk28DP/P9K4ddANx/btR3ozKbhJ2VvegReOP5PA8LG8MqSOg2XlDNi5mfrG+UxqXMCoLavI/FywPCK4OjzUZXustF26eH/H4OZU4feJt8o8kdl5ZrMw8gQb5gojp2Lid0Wzn3HrBIdL9peW88qQOuaOGMtLx53BvoqO9P18G5cuX0B943xO2fhh+xKQIKHG8XStIk+ESC8PwSFMG9oy8ggb5son/E69nDy5bQPS0OCJR6i4HH98XDE5WFLmOVQcMY7nho5hd4dKqvbs4MqlLzCpcQFfWPcBJbSPl4iIVFR4jhKDRHrumTZGmw8qo8iwnkk2SGbqZaRrKiqiepJtlhLerD6JuSPG8cyws9nZqSvd933OhA89j7xj1r5PWTF65A2nrMx7u29p8abdTp0K55xjjbZhJIn1TPKJZN5CI7m4CBOSVoS3B44kMGIs8044h62de9LlwF4uXPkm9Y3zOXf1e1S0tjOHii0tkX1emXgYRkYxMckW4UMp8YjiykKB9/oN8zzyDj+XTV170/HQfsY3vUX98gV8cdU7dGyOsg9GIVFZ6dkQEl0/Y6u2DSMnmJjkKyF2FgWWHTPksEfedT2OpaL5EOetWsQ/vfwQ45veovOh/bktbyoEDc/B1eBBAzQcvUlURQWMHQsvvnj0ffw4QzQMIyOYmOQrs2axcvr3mTv4DALDx7KqaiBlLc2cu/o9bn/td1z04Zt0O5iE65VcU1XlrZMJF454Q37hw4MNDW39XQV3H7ThLMPICWaAzzNWb91DYMkG5i7eyIrNn1PS2sqYT96nfvNSJkyZRM+Fr8L997edaizivZUfiLJfSKxV8+FrJvwQ6lQyVBR2746+oNLWTRhGQWIG+HwmbOrp+rv+gz8fdyZzF2/k/fU7AfhCbU++f9koLjnpWI7pWn/k2ilfizw7CeCaayLnpxp5JljwbR5ie6zt3Bk6dmy7eDKSKERzVmm9BsMoeqxnkm1cg7tFOvDn4ecSGD6WdwaOBGD0wO7Uj+7PxJP60b9Hp8TvHWuHvlmz/M0mS3WNhTkMNIyiwlbAh5EPYrJ9z0HmXXYDc48ZxcLqE1EpYfiWjz13Jp+vomZpiuUzV+KGYaQZG+bKE3buO8SzyzYRWLKR15q20vKFqzlu2yf8w2uPUr98PsdvW+clTMcOibaq2jCMHFHQYiIiE4B7gVLgv1X1BzkuEgC7DzTzYuNm5i7ewPwPt3KwpZVBvTrxjXFDmDTjRkYsfv1of1jpWh+R6HoWwzCMNFCwYiIipcAvgAuBdcDbIvKUqn6Qi/LsP9TCS8u3EFiygRcbt3CguZV+3Tty3Vk11I/uz8kDuyMisO1mmPpe4lurGoZh5DEFKybAGUCTqq4CEJFHgcuBrInJgeYWFny4lblLNvDCB5vZc7CF3l06cNUXBjFpdH9Or+5JSUlYH8SGogzDKEIKWUwGAJ+EfF8HnJnpTJtbWnn9o23MXbyBZ5dtYtf+ZnpUlnPZKf2pP7k/Zw6pojRcQMKxoSjDMIqMQhaTuIjIVGAqQHUKNomWVuWtj7cTWLKBeUs3sX3PQbp2KOOiUccyaXQ/zj2+N+WlJekqtmEYRsFRyGKyHhgU8n2gizuMqs4GZoM3NTiZTF5avpkZf3ifLZ8foFN5KV8a2Zf6k/sxblgfOpaXJlt2wzCMoqKQxeRtYKiIDMYTkauAr6U7k/49OnFadU8mje7HBcOPobKikB+ZYRhGZijYllFVm0XkVuBZvKnBD6nqsnTnM/zYbtx/7enpvq1hGEZRUbBiAqCqTwNP57ochmEY7R2zGhuGYRgpY2JiGIZhpIyJiWEYhpEyJiaGYRhGypiYGIZhGCljYmIYhmGkjImJYRiGkTLtZqdFEfkUiLLJeVx6A1vTWJxcUix1sXrkF1aP/CKd9ahR1T7xErUbMUkFEVnkZ9vKQqBY6mL1yC+sHvlFLuphw1yGYRhGypiYGIZhGCljYuKP2bkuQBoplrpYPfILq0d+kfV6mM3EMAzDSBnrmRiGYRgpY2ISBxGZICIrRKRJRGbkujzhiMhDIrJFRJaGxPUSkedFZKX77OniRUR+5uqyREROC7lmiku/UkSm5KAeg0TkZRH5QESWichthVgXEekoIm+JyGJXj++7+MEistCV9zERqXDxHdz3Jne+NuRed7r4FSJycTbrEVKGUhH5q4gECrUeIrJaRN4XkfdEZJGLK6jflcu/h4g8ISLLRaRRRM7Kq3qoqoUoAW/TrY+AIUAFsBgYmetyhZVxHHAasDQk7h5ghjueAfzQHU8E5gECjAEWuvhewCr32dMd98xyPfoBp7njrsCHwMhCq4srTxd3XA4sdOV7HLjKxd8PTHPHNwP3u+OrgMfc8Uj3e+sADHa/w9Ic/L6+DfwOCLjvBVcPYDXQOyyuoH5XrgyPADe54wqgRz7VI6s/zEILwFnAsyHf7wTuzHW5IpSzlrZisgLo5477ASvc8QPA1eHpgKuBB0Li26TLUZ3+BFxYyHUBKoF3gTPxFpCVhf+u8HYKPcsdl7l0Ev5bC02XxfIPBF4ELgACrlyFWI/VHC0mBfW7AroDH+Ps3PlYDxvmis0A4JOQ7+tcXL7TV1U3uuNNQF93HK0+eVVPN0RyKt5bfcHVxQ0NvQdsAZ7HexvfoarNEcp0uLzu/E6gijyoB/BfwHeBVve9isKshwLPicg7IjLVxRXa72ow8CnwsBt2/G8R6Uwe1cPEpMhR7/WjYKbsiUgX4A/A7aq6K/RcodRFVVtU9RS8N/szgOE5LlLCiMgkYIuqvpPrsqSBc1X1NOAS4BYRGRd6skB+V2V4w9n3qeqpwB68Ya3D5LoeJiaxWQ8MCvk+0MXlO5tFpB+A+9zi4qPVJy/qKSLleELSoKpPuuiCrAuAqu4AXsYbDuohImURynS4vO58d2Abua/HOcBlIrIaeBRvqOteCq8eqOp697kF+F88gS+039U6YJ2qLnTfn8ATl7yph4lJbN4GhroZLBV4hsWnclwmPzwFBGdpTMGzPwTjr3MzPcYAO10X+VngIhHp6WaDXOTisoaICPAg0KiqPwk5VVB1EZE+ItLDHXfCs/s04onKlVHqEazflcBL7g3zKeAqN0tqMDAUeCs7tQBVvVNVB6pqLd7v/iVVnUyB1UNEOotI1+Ax3u9hKQX2u1LVTcAnInKCixoPfJBX9ciWAalQA96siA/xxr1n5ro8Ecr3e2AjcAjv7eVGvLHqF4GVwAtAL5dWgF+4urwP1IXc5wagyYXrc1CPc/G66EuA91yYWGh1AU4G/urqsRT4Fxc/BK8RbQL+B+jg4ju6703u/JCQe8109VsBXJLD39gXOTKbq6Dq4cq72IVlwf/hQvtdufxPARa539Yf8WZj5U09bAW8YRiGkTI2zGUYhmGkjImJYRiGkTImJoZhGEbKmJgYhmEYKWNiYhiGYaSMiYlhGIaRMiYmhmEYRsqYmBiGYRgp8/8BKZf2WbAlUVUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sqft_living, price, 'ro')\n",
    "plt.plot([0, 6000], [theta0, theta1 * 6000 + theta0])\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 57947526161.28836, r^2 : 0.49670880166311404, rse : 240722.92404606662\n"
     ]
    }
   ],
   "source": [
    "def pred(x):\n",
    "    return theta0 + theta1 * x\n",
    "predicted = [pred(sqft_living[i]) for i in range(0, n)]\n",
    "mse = mean_squared_error(price, predicted)\n",
    "r2 = r2_score(price, predicted)\n",
    "rse = math.sqrt(mse)\n",
    "print(\"MSE : {}, r^2 : {}, rse : {}\".format(mse, r2, rse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import matmul\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import norm\n",
    "y = trainScaled[\"price\"]\n",
    "xPandas = trainScaled.drop(['price'], axis=1)\n",
    "xPandas.insert(0, 0, 1)\n",
    "X = xPandas.values\n",
    "n = X.shape[0]\n",
    "d = X.shape[1] - 1\n",
    "XT = X.transpose()\n",
    "theta = matmul(matmul(inv(matmul(XT, X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.16683573e-13, -1.24298034e-02, -4.73053034e-02,  3.11743954e-01,\n",
       "        4.64119237e-02,  6.66237278e-02,  1.88841504e-01,  1.38390601e-01,\n",
       "        3.70339949e-02,  2.72721961e-01,  5.29109366e-02,  2.90411911e-02,\n",
       "       -1.99349813e-01,  5.09001715e-02,  2.30979722e-01, -3.05082836e-03,\n",
       "        1.34321094e-01, -3.81060382e-02])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.2780124433924648, r^2 : 0.7217092658734054, rse : 0.5272688530460193\n",
      "MSE on test: 0.5112846884712547, r^2 on test: 0.6465670281201799, rse on test : 0.7150417389714077\n"
     ]
    }
   ],
   "source": [
    "def pred(theta, x):\n",
    "    return sum(theta * x)\n",
    "predicted = [pred(theta, X[i]) for i in range(0, n)]\n",
    "mse = mean_squared_error(y, predicted)\n",
    "r2 = r2_score(y, predicted)\n",
    "rse = math.sqrt(mse)\n",
    "x_test_scaled = testScaled.drop([\"price\"], axis=1)\n",
    "x_test_scaled.insert(0,0,1)\n",
    "X_test = x_test_scaled.values\n",
    "test_pred = [pred(theta, X_test[i]) for i in range(0,n)]\n",
    "mse_test = mean_squared_error(y_test_scaled, test_pred)\n",
    "r2_test = r2_score(y_test_scaled, test_pred)\n",
    "rse_test = math.sqrt(mse_test)\n",
    "print(\"MSE : {}, r^2 : {}, rse : {}\".format(mse, r2, rse, mse_test))\n",
    "print(\"MSE on test: {}, r^2 on test: {}, rse on test : {}\".format(mse_test, r2_test, rse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing closed form and package \n",
    "The coeffecients are more even from the closed form. They all have similar magnitudes than the package given ones where some features had much bigger coeffecients. This model has similar stats for the test data, but it still may have overfitted on the test data as the high r^2 and lower RSE may indicate that. The validation data still seemed to have fitted well however. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.01, number of iterations: 15\n",
      "theta: [5.622649013048432e-15, 0.03927778691985031, 0.07040747854589939, 0.1174157241960177, 0.017307731270750852, 0.03239252097125081, 0.06962848731941493, 0.0884363452430802, 0.020922259905258412, 0.11047371576449541, 0.09279505367789762, 0.06862207724379565, -0.023997819931495464, 0.03360796982645111, 0.08469118923408267, -0.010461955533740427, 0.10759828141282586, 0.018807847427967678]\n",
      "MSE train: 0.40318706042696695\n",
      "MSE test: 0.688984262651524\n",
      "alpha: 0.01, number of iterations: 25\n",
      "theta: [1.2050683784181614e-14, 0.03719742605272535, 0.07684711216156895, 0.14194914389200616, 0.016155205127643818, 0.03453739126238882, 0.09699561669813177, 0.11637445028015378, 0.030772021040379374, 0.1369086967717433, 0.11028000231233023, 0.08629674582229521, -0.04882229505433592, 0.04684664828308554, 0.12122337630186948, -0.02266509826177874, 0.13071963629276884, 0.016870804590172667]\n",
      "MSE train: 0.33887232477893003\n",
      "MSE test: 0.5981706928180553\n",
      "alpha: 0.01, number of iterations: 50\n",
      "theta: [2.8980026156588677e-14, 0.017737327042157428, 0.07022218831481823, 0.16108776954583587, 0.010727709329839743, 0.03278067205121349, 0.13588356155497638, 0.14628964206411826, 0.0428987244594199, 0.16678101747870488, 0.12525968338417065, 0.09773754647133841, -0.09427718430976736, 0.06273185504934205, 0.17714214402773001, -0.038819157502844516, 0.15107847653089568, 0.007921282667920587]\n",
      "MSE train: 0.29333397498894986\n",
      "MSE test: 0.5338535693382401\n",
      "alpha: 0.01, number of iterations: 60\n",
      "theta: [3.5590996816381454e-14, 0.010335331192946832, 0.06668692041750285, 0.16370787361491293, 0.009472723516946389, 0.03224152396499135, 0.14499702454350671, 0.1508258092754578, 0.044880755214434194, 0.17418482037726168, 0.1284773146712304, 0.09725914349666193, -0.10615121433461525, 0.06526639715680156, 0.19089623978289896, -0.04061510229882193, 0.15460519338087447, 0.0050491265758369494]\n",
      "MSE train: 0.28727603028272314\n",
      "MSE test: 0.525323994669196\n",
      "alpha: 0.01, number of iterations: 100\n",
      "theta: [5.952286219468307e-14, -0.010738950523330812, 0.056724487990233836, 0.1678461337091595, 0.0079383534139162, 0.03079548681694791, 0.16532707516662173, 0.1546858903445629, 0.04723476143906653, 0.19552084490717403, 0.13712474450553794, 0.09025610489837539, -0.13518344771140398, 0.06713432483204305, 0.22123444152837793, -0.037485091686752514, 0.1611403717365458, -0.003136172923331235]\n",
      "MSE train: 0.27815604191853216\n",
      "MSE test: 0.5119104782807268\n",
      "alpha: 0.05, number of iterations: 15\n",
      "theta: [4.552297427906637e-14, -0.00044261054300827156, 0.06145724424130092, 0.16657435890198882, 0.007991309119678047, 0.03166993815831153, 0.15686647809989016, 0.1555802202067559, 0.0469988126745612, 0.18435696867505535, 0.1328876989606185, 0.09517594767834456, -0.12194990116196959, 0.0679460961398682, 0.20909327784435075, -0.04176369632247984, 0.1589374168569805, 0.0010878909814336457]\n",
      "MSE train: 0.28145178802849546\n",
      "MSE test: 0.5168319384624818\n",
      "alpha: 0.05, number of iterations: 25\n",
      "theta: [7.265952839397016e-14, -0.01959203196716301, 0.05273478374360265, 0.16887854226663204, 0.008120906654958408, 0.02976743014110467, 0.1724287259566019, 0.15322496387647372, 0.04727991882740513, 0.20580506326266934, 0.14076647211829815, 0.08590802533147861, -0.1468543491793442, 0.06595695240267532, 0.23092632803091348, -0.033019994512136594, 0.16268856569277299, -0.007079611265163409]\n",
      "MSE train: 0.2761932301688888\n",
      "MSE test: 0.5086227473716532\n",
      "alpha: 0.05, number of iterations: 50\n",
      "theta: [1.036538577192658e-13, -0.033286322102059174, 0.04884809162563661, 0.1698867606583512, 0.013269239169989245, 0.02488865696947802, 0.18318422167450568, 0.14451764803769127, 0.0444914867708834, 0.2349804060280472, 0.1452822274058214, 0.0799808116265256, -0.17347396525718456, 0.058880810365097784, 0.23685635393688884, -0.017400717175162318, 0.15758422322106147, -0.01917326862038394]\n",
      "MSE train: 0.2739376400190959\n",
      "MSE test: 0.5034584621056177\n",
      "alpha: 0.05, number of iterations: 60\n",
      "theta: [1.0792722826558075e-13, -0.034825339456180146, 0.04929848441427647, 0.16973078460473645, 0.015608354882001593, 0.02411635565178274, 0.18465889639066174, 0.1429950209052906, 0.04328925761654719, 0.2420769889505828, 0.14522471883651072, 0.07977442474928634, -0.17915406087465732, 0.05717036818764328, 0.2359750063745193, -0.014194740297260273, 0.15443612581816182, -0.02221722328165546]\n",
      "MSE train: 0.2736782899837394\n",
      "MSE test: 0.5025572494119198\n",
      "alpha: 0.05, number of iterations: 100\n",
      "theta: [1.1374634567573594e-13, -0.03667584825135308, 0.0518826454904671, 0.16855736196805682, 0.023025368656350728, 0.023600345124024757, 0.18689444592270882, 0.141363732885307, 0.04020342857065847, 0.25872898500093794, 0.14379275550081938, 0.07997279708668895, -0.19130994496908166, 0.053430402287453355, 0.23303243194983117, -0.007693626075207479, 0.1444955198896388, -0.029776915936383676]\n",
      "MSE train: 0.27329348116127095\n",
      "MSE test: 0.5008618089539066\n",
      "alpha: 0.1, number of iterations: 15\n",
      "theta: [8.398228779071815e-14, -0.025625987952028105, 0.05019857432300275, 0.16944698701381364, 0.008759392728241548, 0.02845331833311991, 0.17690821653381958, 0.1507246941092841, 0.04695225005794341, 0.2143560682044867, 0.1432294652666901, 0.08271170137111687, -0.15550029614824343, 0.06411349846711992, 0.23588151245716188, -0.028264334489350684, 0.1629515213184397, -0.010472475932967138]\n",
      "MSE train: 0.2751980879524598\n",
      "MSE test: 0.5067196516553183\n",
      "alpha: 0.1, number of iterations: 25\n",
      "theta: [1.0448470977308945e-13, -0.03360106559748207, 0.04870234201523222, 0.16994477247948814, 0.013271096805335244, 0.024717033496736915, 0.18342137331260075, 0.1442585912785397, 0.044471874553452764, 0.23549334996627222, 0.14542764028008895, 0.0798402542989216, -0.1739864496407254, 0.05873394569017664, 0.23698613995327444, -0.017052406986088897, 0.15761998457717152, -0.01938423625458472]\n",
      "MSE train: 0.27391565595650064\n",
      "MSE test: 0.5033844825929666\n",
      "alpha: 0.1, number of iterations: 50\n",
      "theta: [1.1382846887286748e-13, -0.03671110568657588, 0.0519257407455073, 0.16853986401005963, 0.023129941308097344, 0.023594001688603032, 0.18693392671288372, 0.14132602269926714, 0.04014575057559124, 0.25900348649085286, 0.14376773834284018, 0.07998217513441172, -0.19152034213171878, 0.05336547108775102, 0.2329759080628342, -0.007587918631537228, 0.14434006773735045, -0.029883948312015143]\n",
      "MSE train: 0.27328973417389796\n",
      "MSE test: 0.5008378562201217\n",
      "alpha: 0.1, number of iterations: 60\n",
      "theta: [1.1478650252527703e-13, -0.03685447062572966, 0.05282741043462863, 0.1680678334029131, 0.02555915897024027, 0.023675146953985003, 0.18727282540484178, 0.14139217148982966, 0.03941644285716648, 0.2632777163871262, 0.14320404831024228, 0.08004034575618796, -0.19432397183800781, 0.05248736439386029, 0.23224078459545316, -0.006063261387536609, 0.14127142955558966, -0.032095643423651676]\n",
      "MSE train: 0.2732380653593093\n",
      "MSE test: 0.5005176236270562\n",
      "alpha: 0.1, number of iterations: 100\n",
      "theta: [1.1635448160518538e-13, -0.03689477905403049, 0.054296174258855266, 0.16730537567980078, 0.030262787794045287, 0.023756458075512847, 0.18772303403001955, 0.14184735284927505, 0.03840033965900196, 0.2701210024947178, 0.14236170344448967, 0.08001486153923548, -0.1984587673252476, 0.05119050290281162, 0.23119975037566964, -0.00365648941099475, 0.13592571492977754, -0.03638637539656568]\n",
      "MSE train: 0.27319540933538433\n",
      "MSE test: 0.500110933716636\n",
      "alpha: 0.15, number of iterations: 15\n",
      "theta: [1.0244583514840143e-13, -0.03287071096097382, 0.04842382189479137, 0.17005070564785732, 0.012038911174975797, 0.025123954915757148, 0.18269983040458668, 0.145054572832642, 0.04513694453941903, 0.23183500613420177, 0.1455271012914463, 0.07987458411238245, -0.1710512018611135, 0.05961482313268591, 0.23758526001478752, -0.018670784762332287, 0.15934128695538408, -0.017809032856325197]\n",
      "MSE train: 0.27407163736654183\n",
      "MSE test: 0.5038566249963705\n",
      "alpha: 0.15, number of iterations: 25\n",
      "theta: [1.1174106639977311e-13, -0.03617137931011293, 0.050340374813494876, 0.1693169371684438, 0.018993209106004095, 0.023550411842202346, 0.18610376659842276, 0.1416280431929712, 0.04166241766835688, 0.25079302297968425, 0.14474077295915894, 0.07980744219154456, -0.185822200604628, 0.05514071360004749, 0.23448965298176472, -0.010591780850815037, 0.1498123726854357, -0.026001990384478025]\n",
      "MSE train: 0.2734416182668348\n",
      "MSE test: 0.5015843419627928\n",
      "alpha: 0.15, number of iterations: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [1.1570402969063306e-13, -0.03690366883224948, 0.053701564132427056, 0.167600057952594, 0.028117413434311286, 0.023749414789156688, 0.18754419998323868, 0.14160250659285958, 0.03878696141731581, 0.2673052003573672, 0.14267203334092987, 0.08005139382093467, -0.19683027087172245, 0.051702086137140356, 0.23160119738595467, -0.004642950991090086, 0.13822026364383666, -0.034413529781304415]\n",
      "MSE train: 0.27320686365519775\n",
      "MSE test: 0.5002633578959712\n",
      "alpha: 0.15, number of iterations: 60\n",
      "theta: [1.161733043097968e-13, -0.036898708938784906, 0.05414259931101384, 0.1673745298887415, 0.029636929942911977, 0.023761914502386176, 0.1876739893221255, 0.14177353924184538, 0.03849753291250426, 0.2693709201156053, 0.1424314090525417, 0.08002890287301295, -0.19803854620396383, 0.05132315516209208, 0.2313024307142517, -0.0039192485388777135, 0.13655974035780113, -0.035805293134588675]\n",
      "MSE train: 0.2731975967140817\n",
      "MSE test: 0.5001502137352178\n",
      "alpha: 0.15, number of iterations: 100\n",
      "theta: [1.1656539067317344e-13, -0.03689111455625527, 0.0544805589782418, 0.16723298707142606, 0.03110283187917904, 0.023742408201086498, 0.18778693219503084, 0.1419458458307262, 0.03828469977462199, 0.27105232593177064, 0.14229185577548903, 0.07999469980257895, -0.1989688989707916, 0.05102828995449057, 0.2310751962009665, -0.0033291898285892404, 0.13511185684888607, -0.03717281356888182]\n",
      "MSE train: 0.2731936672812985\n",
      "MSE test: 0.5000632927643183\n",
      "alpha: 0.2, number of iterations: 15\n",
      "theta: [7.536837820509846e-14, 0.18670501946249377, 0.379115692225618, 0.535771147799849, 0.15601839693582067, 0.22862632605411518, 0.2296555098746266, 0.24831834662914498, -0.002634809345918615, 0.5830031442890401, 0.5035357310604565, 0.1727543371118502, 0.03315672161539868, 0.05418638822770612, 0.27150703086791306, 0.1546015221575624, 0.4993929626049111, 0.12878774561229728]\n",
      "MSE train: 4.637297365426604\n",
      "MSE test: 4.947006944867541\n",
      "alpha: 0.2, number of iterations: 25\n",
      "theta: [3.9412451080522756e-14, 0.45002473190437187, 0.7753303642635997, 0.970676815064355, 0.330791393313407, 0.4727104315595564, 0.2846358769688263, 0.37344434448169794, -0.06023531292130696, 1.0039613034413932, 0.9287524698883965, 0.28411269572399844, 0.2761873257055647, 0.047484549810687955, 0.31090087139629613, 0.3609464219219451, 0.9006535200128375, 0.30208910410024153]\n",
      "MSE train: 21.24190220767971\n",
      "MSE test: 22.999176513871905\n",
      "alpha: 0.2, number of iterations: 50\n",
      "theta: [6.479945691140189e-13, -3.5002642853452346, -5.091720463206444, -5.539851583373385, -2.1569851390016144, -3.17154287065546, -0.5068538144044936, -1.510034385691891, 0.7517177165188561, -5.025882382544571, -5.442888927713809, -1.372132702483679, -3.529050705444229, 0.092082188950912, -0.3240449106995682, -2.624100786376284, -5.2473229264113215, -2.3998341700826087]\n",
      "MSE train: 1061.6441978326493\n",
      "MSE test: 1192.1967789223884\n",
      "alpha: 0.2, number of iterations: 60\n",
      "theta: [1.2803710314202024e-12, -7.628929669484775, -11.226130240642432, -12.343368507872267, -4.763683861588876, -6.980663925528544, -1.3348039137510381, -3.479152207371983, 1.601977871729206, -11.338514585365438, -12.101076191076839, -3.103250078265813, -7.499809646991886, 0.14070841096924402, -0.9860409455746382, -5.747670350507072, -11.665318975797625, -5.217960717123902]\n",
      "MSE train: 5100.4609889957455\n",
      "MSE test: 5710.17122329525\n",
      "alpha: 0.2, number of iterations: 100\n",
      "theta: [2.6971076061421688e-11, -175.3427169793717, -260.4234474698303, -288.71170300396193, -110.68491590487241, -161.7131996625517, -34.970032225023566, -83.4720040664819, 36.14527395312447, -267.80361643094926, -282.56602221069454, -73.42346562999293, -168.7801524937559, 2.1220101856767744, -27.872884199420312, -132.6448261040825, -272.344686290476, -119.66465246905301]\n",
      "MSE train: 2719330.594654518\n",
      "MSE test: 3037149.817628547\n"
     ]
    }
   ],
   "source": [
    "def gradient(alpha, iterations, e=0.0001):\n",
    "    theta = [0 for i in range(d+1)]\n",
    "    count = 0\n",
    "    def h(theta, i):\n",
    "        return sum(theta * X[i])\n",
    "    while count < iterations:\n",
    "        norm = 0\n",
    "        hVals = [h(theta, i) for i in range(n)]\n",
    "        for j in range(d+1):\n",
    "            val = 0\n",
    "            for i in range(n):\n",
    "                val += (hVals[i] - y[i]) * X[i,j]\n",
    "            newTheta = theta[j] - alpha * (2/n) * (val)\n",
    "            norm += (newTheta - theta[j])**2\n",
    "            theta[j] = newTheta\n",
    "        if math.sqrt(norm) < e:\n",
    "            break\n",
    "        count += 1\n",
    "    return theta\n",
    "alphas = [0.01, 0.05, 0.1, 0.15, 0.2]\n",
    "iterations = [15, 25, 50, 60, 100]\n",
    "def mse_train(theta):\n",
    "    return mean_squared_error(y, [pred(theta, X[i]) for i in range(0, n)])\n",
    "def mse_test(theta):\n",
    "    return mean_squared_error(y_test_scaled, [pred(theta, X_test[i]) for i in range(0, n)])\n",
    "for alpha in alphas:\n",
    "    for iteration in iterations:\n",
    "        print(\"alpha: {}, number of iterations: {}\".format(alpha, iteration))\n",
    "        theta = gradient(alpha, iteration)\n",
    "        print(\"theta: {}\".format(str(theta)))\n",
    "        print(\"MSE train: {}\".format(mse_train(theta)))\n",
    "        print(\"MSE test: {}\".format(mse_test(theta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "I got virtually the same MSE as the closed form using 0.01 alpha and 100 iterations. The MSE matched both the training and testing set. Different learning rates greatly vary the MSE and as I increased the alpha, there was a stage where it seemed to stop converging as the learning rate probably made the descent jump over convergence point over and over again.  This caused the MSE to be very high as theta did not converge. The more iterations and smaller alpha gave best results, but it took much longer to run especially if convergence was not close to happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "![5A](5a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l = 5000, MSE : 0.548091625339674, r^2 : 0.45135973439471455, rse : 0.7403321047608796\n",
      "test l = 5000, MSE : 0.8880610802039898, r^2 : 0.38611487129455513, rse : 0.7403321047608796\n",
      "l = 10000, MSE : 0.680032000864685, r^2 : 0.3192872864217292, rse : 0.8246405282695515\n",
      "test l = 10000, MSE : 1.0554861739577892, r^2 : 0.27037984189324016, rse : 0.8246405282695515\n",
      "l = 500, MSE : 0.2980984886490465, r^2 : 0.7016031144654156, rse : 0.545983963728832\n",
      "test l = 500, MSE : 0.5507787923922318, r^2 : 0.6192661547804021, rse : 0.545983963728832\n",
      "l = 100, MSE : 0.27527222441881644, r^2 : 0.7244522278089895, rse : 0.5246639156820454\n",
      "test l = 100, MSE : 0.5089028885264261, r^2 : 0.6482134819489478, rse : 0.5246639156820454\n",
      "l = 50, MSE : 0.2738118124857615, r^2 : 0.7259141016158512, rse : 0.5232703053735818\n",
      "test l = 50, MSE : 0.5042189992954668, r^2 : 0.6514512884551501, rse : 0.5232703053735818\n",
      "l = 0, MSE : 0.2780124433924648, r^2 : 0.7217092658734054, rse : 0.5272688530460193\n",
      "test l = 0, MSE : 0.5112846884712547, r^2 : 0.6465670281201799, rse : 0.5272688530460193\n",
      "l = 80, MSE : 0.274612383662992, r^2 : 0.725112729066071, rse : 0.5240347160856731\n",
      "test l = 80, MSE : 0.5069939867151536, r^2 : 0.6495330380698285, rse : 0.5240347160856731\n",
      "l = 60, MSE : 0.2740503373031938, r^2 : 0.725675338034838, rse : 0.5234981731612764\n",
      "test l = 60, MSE : 0.5051299339245774, r^2 : 0.6508215916533204, rse : 0.5234981731612764\n"
     ]
    }
   ],
   "source": [
    "from numpy import add\n",
    "from numpy import identity\n",
    "def ridge(l):\n",
    "    lI = l * identity(d+1)\n",
    "    return matmul(matmul(inv(add(matmul(XT, X), lI)), XT), y)\n",
    "ls = [5000, 10000, 500, 100, 50, 0, 80, 60]\n",
    "for l in ls:\n",
    "    theta = ridge(l)\n",
    "    predicted = [pred(theta, X[i]) for i in range(0, n)]\n",
    "    mse = mean_squared_error(y, predicted)\n",
    "    r2 = r2_score(y, predicted)\n",
    "    rse = math.sqrt(mse)\n",
    "    predicted_test = [pred(theta, X_test[i]) for i in range(0, n)]\n",
    "    mseTest = mean_squared_error(y_test_scaled, predicted_test)\n",
    "    r2Test = r2_score(y_test_scaled, predicted_test)\n",
    "    rseTest = math.sqrt(mse)\n",
    "    print(\"l = {}, MSE : {}, r^2 : {}, rse : {}\".format(l, mse, r2, rse))\n",
    "    print(\"test l = {}, MSE : {}, r^2 : {}, rse : {}\".format(l, mseTest, r2Test, rseTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Ridge\n",
    "The ridge regression fit better with smaller lambda values and caused the r^2 value to higher than the closed form or the package models. The MSE did not change that much, but this could mean the model also overfitted on the training set as well. The testing set shows that the model still fit well on the validation set equivalent to the package and closed form solutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
